{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04c10af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b27610e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03705b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb99fe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet')\n",
    "# Convert all column names to lowercase\n",
    "df1.columns = [col.lower() for col in df1.columns]\n",
    "\n",
    "df2 = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet')\n",
    "df2.columns = [col.lower() for col in df2.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c2b9c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendorid</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>ratecodeid</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>pulocationid</th>\n",
       "      <th>dolocationid</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:32:10</td>\n",
       "      <td>2023-01-01 00:40:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:55:08</td>\n",
       "      <td>2023-01-01 01:01:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>43</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendorid tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2023-01-01 00:32:10   2023-01-01 00:40:36              1.0   \n",
       "1         2  2023-01-01 00:55:08   2023-01-01 01:01:27              1.0   \n",
       "\n",
       "   trip_distance  ratecodeid store_and_fwd_flag  pulocationid  dolocationid  \\\n",
       "0           0.97         1.0                  N           161           141   \n",
       "1           1.10         1.0                  N            43           237   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2          9.3    1.0      0.5         0.0           0.0   \n",
       "1             1          7.9    1.0      0.5         4.0           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                    1.0          14.3                   2.5          0.0  \n",
       "1                    1.0          16.9                   2.5          0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cde1f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "# Reset indexes of original DataFrames\n",
    "df1.reset_index(drop=True, inplace=True)\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "df = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7faa437a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5980721 entries, 0 to 5980720\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   vendorid               int64         \n",
      " 1   tpep_pickup_datetime   datetime64[ns]\n",
      " 2   tpep_dropoff_datetime  datetime64[ns]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   ratecodeid             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   pulocationid           int64         \n",
      " 8   dolocationid           int64         \n",
      " 9   payment_type           int64         \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  airport_fee            float64       \n",
      "dtypes: datetime64[ns](2), float64(12), int64(4), object(1)\n",
      "memory usage: 867.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1d01e7",
   "metadata": {},
   "source": [
    "### Q1. Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c415953e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 19\n"
     ]
    }
   ],
   "source": [
    "# Count the number of columns in the DataFrame\n",
    "num_columns = df1.shape[1]\n",
    "\n",
    "# Print the number of columns\n",
    "print(\"Number of columns:\", num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4031c8",
   "metadata": {},
   "source": [
    "### Q2. Computing duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5bdf63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of duration column: 42.594351241920904\n"
     ]
    }
   ],
   "source": [
    "# Calculate the duration of each trip in minutes and store it in a new column 'duration'\n",
    "# The duration is calculated as the difference between drop-off and pickup times\n",
    "df1['duration'] = df1.tpep_dropoff_datetime - df1.tpep_pickup_datetime\n",
    "# Convert the duration from timedelta to minutes by dividing total seconds by 60\n",
    "df1.duration = df1.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "# Calculate the standard deviation of the 'duration' column\n",
    "duration_std1 = df1['duration'].std()\n",
    "\n",
    "# Print the standard deviation\n",
    "print(\"Standard deviation of duration column:\", duration_std1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b681d1b",
   "metadata": {},
   "source": [
    "### Q3. Dropping outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c483b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of records remaining after dropping outliers: 98.1220282212598 %\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of records before removing outliers\n",
    "total_records_before = len(df1)\n",
    "\n",
    "# Filter the DataFrame to keep only records where the duration is between 1 and 60 minutes\n",
    "df1_filtered = df1[(df1['duration'] >= 1) & (df1['duration'] <= 60)]\n",
    "\n",
    "# Count the number of records after removing outliers\n",
    "total_records_after = len(df1_filtered)\n",
    "\n",
    "# Calculate the fraction of records remaining after dropping outliers\n",
    "fraction_remaining = total_records_after / total_records_before *100\n",
    "\n",
    "# Print the fraction of records remaining\n",
    "print(\"Fraction of records remaining after dropping outliers:\", fraction_remaining, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07da886f",
   "metadata": {},
   "source": [
    "### Q4. One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90c06185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of the feature matrix (number of columns): 515\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame to a list of dictionaries\n",
    "data_list = df1_filtered[['pulocationid', 'dolocationid']].astype(str).to_dict(orient='records')\n",
    "\n",
    "\n",
    "#data_list\n",
    "\n",
    "# Initialize and fit the dictionary vectorizer\n",
    "dv  = DictVectorizer(sparse=True)\n",
    "#dv.fit(data_list)\n",
    "\n",
    "# Transform the data to obtain the feature matrix\n",
    "feature_matrix = dv.fit_transform(data_list)\n",
    "train_dicts = dv.fit_transform(data_list)\n",
    "# Get the dimensionality of the feature matrix (number of columns)\n",
    "num_columns = feature_matrix.shape[1]\n",
    "\n",
    "# Print the dimensionality of the feature matrix\n",
    "print(\"Dimensionality of the feature matrix (number of columns):\", num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15d93848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.distplot(y_pred, label='prediction')\n",
    "#sns.distplot(y_train, label='actual')\n",
    "\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8337baf5",
   "metadata": {},
   "source": [
    "### Q 5 and 6. Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818cf257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "        df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "    elif filename.endswith('.parquet'):\n",
    "        df = pd.read_parquet(filename)\n",
    "\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['pulocationid', 'dolocationid']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4afe7aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet')\n",
    "df_val = read_dataframe('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a619ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical = ['PU_DO'] #'PULocationID', 'DOLocationID']\n",
    "#categorical = ['pulocationid', 'dolocationid']\n",
    "#numerical = ['trip_distance']\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "#train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "train_dicts = df_train[['pulocationid', 'dolocationid']].astype(str).to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[['pulocationid', 'dolocationid']].astype(str).to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c078d6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51bb7d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training data: 7.6492610279057605\n",
      "RMSE on validation data: 7.81183265470218\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict on the training data\n",
    "y_train_pred = lr.predict(X_train)\n",
    "\n",
    "# Calculate RMSE on the training data\n",
    "rmse_train = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "print(\"RMSE on training data:\", rmse_train)\n",
    "\n",
    "\n",
    "# Calculate RMSE on the validation data\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "rmse_val = mean_squared_error(y_val, y_pred, squared=False)\n",
    "print(\"RMSE on validation data:\", rmse_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1351dafe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
